# Ollama LLaMA2 Chatbot ğŸ¤–

A local AI chatbot built using **Streamlit**, **FastAPI**, and **Ollama (LLaMA2)**.  
This project demonstrates how to build a full-stack chatbot that runs completely on a local machine without relying on paid APIs.

---

## ğŸš€ Features

- ğŸ’¬ Interactive chat UI using Streamlit  
- âš¡ FastAPI backend for handling requests  
- ğŸ§  LLaMA2 model served locally via Ollama  
- ğŸ”„ Chat history maintained during session  
- ğŸ” Fully local & private (no external API calls)

---

## ğŸ› ï¸ Tech Stack

- **Python 3.10+**
- **Streamlit** â€“ Frontend UI
- **FastAPI** â€“ Backend API
- **Ollama** â€“ Local LLaMA2 model
- **Requests** â€“ API communication

---

## ğŸ“‚ Project Structure

```text
ollama-llama2-chatbot/
â”‚
â”œâ”€â”€ app.py        # FastAPI backend
â”œâ”€â”€ chat.py       # Ollama / LLaMA2 interaction logic
â”œâ”€â”€ ui.py         # Streamlit frontend
â”œâ”€â”€ screenshots/  # Project screenshots
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md



# Ollama LLaMA2 Chatbot

A chatbot built using Streamlit, FastAPI, and Ollama LLaMA2.

## Screenshots

![Chat UI](screenshots/chat-ui.png)
